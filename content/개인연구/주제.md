# 개인 연구
| 번호 | 주제                                                                                                                                                                                                                                                                                                                                     |
| ---- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1    | [[Optimizer#Gradient Descent\|Gradient Descent]] 과정에서 gradient의 반대 방향으로 가중치를 조절해 기존과 반대로 분류 문제에서 아닌 것을 걸러내는 모델? 문제 마다 minimize와 maximize 중 더 쉬운 게 있지 않을까.                                                                                                                         |
| 2    | 머신러닝, 유전 알고리즘 등을 통한 작도                                                                                                                                                                                                                                                                                                   |
| 3    | 회로 기반 [[Optimizer#Gradient Descent\|Gradient Descent]] (전람회 마무리)                                                                                                                                                                                                                                                               |
| 4    | Genetic Algorithm 사용할 때 탐색의 후보 중 일부가 이전 세대로 부터 넘어오는데, 이중 일부를 적합도에 따른 history에서 상위에 rank한 개체로 선택하기                                                                                                                                                                                       |
| 5    | optimization에서 사용되는 error는 결국 각 정답에 대한 오차 공간을 summation한 거니까, 정답 공간에서 정답의 밀도가 높은 구간을 찾아내는 게 global minima에 근접하는 데에 도움을 주지 않을까? -> error는 결국 정답 분포의 weighed sum?                                                                                                     |
| 6    | [[Fully Connected Layer]] 이후 [[Support Vector Machine]]을 통해 classification을 수행하는 경우가 많은데, 그러면 fully connected layer는 결국 support vector machine을 위한 공간을 구성하는 역할?                                                                                                                                        |
| 7    | EEG 할 때 CNN 쓰는 경우 많이 봤는데, 얘는 옆 채널과 직접적인 연관이 없는 경우가 있기에, kernel을 사용하는 것이 적합하지 않을지도 모른다. scanning하는 것 처럼 kernel의 세로 길이를 채널 수에 맞추어 embedding vector 만드는 형식이 나을 수도 있겠다. [[Spatial Pyramid Pooling]] 처럼 kernel 가로 길이 조절해도 좋고.<br>[[Scanner-CNN]] |
| 8    | 각 샘플에 대한 최적의 parameter들을 찾으면 global optima를 이루는 parameter를 찾는 것은 parameter들에 대한 Weber problem으로 볼 수 있지 않을까?<br>[[parameter optimization to Weber's problem]]                                                                                                                                                |
# 토이 프로젝트
| 번호 | 주제                                |
| ---- | ----------------------------------- |
| 1    | LLM으로 노트 필기 검증              |
| 2    | 이디저디 특별실 인원 수정 기능 추가 |
| 3    | 실시간 수업 이해도 피드백           |
| 4    | 인스타그램 네트워크 빌더 업데이트   |
| 5    | 바디캠으로 손이 물체에 가까워지면 팔찌 등으로 진동을 통해 알려주기                                 |
# 몰루
| 번호 | 주제 |
| --- | --- |
| 1    | 동형 암호 기반 드론 촬영물 모자이크  |